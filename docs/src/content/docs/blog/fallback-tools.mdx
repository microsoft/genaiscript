---
title: Fallback Tools
date: 2024-11-07
authors: pelikhan
tags:
  - openai
  - tools
canonical_url: https://microsoft.github.io/genaiscript/blog/fallback-tools
description: Support for Tools.
cover:
  alt: An image in retro 8-bit style showing a digital workspace. On the left,
    there are icons with lines connecting them, symbolizing the idea of
    "fallback tools." On the right, geometrical shapes represent binary code
    processing related to tool-enabled LLMs. The background consists of basic
    geometric shapes that give a corporate and tech-focused feel, using a
    consistent 5-color scheme without any human figures or text.
  image: ./fallback-tools.png
excerpt: Enhance your LLM's capabilities with fallback tools. When your chosen
  model lacks native tool support, fallback tools step in, teaching the model
  how to utilize external resources for better problem-solving. Automatically
  enabled for recognized models, this feature ensures efficient workflows and
  can be manually configured for broader compatibility. Stay ahead by
  integrating smarter solutions.

---

import BlogNarration from "../../../components/BlogNarration.astro"

<BlogNarration />

[Tools](/genaiscript/reference/scripts/tools) is a powerful feature of LLM models
that allows you to augment the LLM reasoning with external tools.

These days, many LLM models come with a built-in support for tools. However, some of them
don't... like [OpenAI's o1-preview and o1-mini](https://platform.openai.com/docs/guides/reasoning).

## Fallback tools

With GenAIScript 1.72.0, we introduce the concept of **fallback tools**.
Basically, it consists of a [system script](/genaiscript/reference/scripts/system#systemtool_calls) that "teaches" the LLM model about available tools and how to call them.

```js wrap
$`## Tool support

You can call external tools to help generating the answer of the user questions.

- The list of tools is defined in TOOLS. Use the description to help you choose the best tools.
- Each tool has an id, description, and a JSON schema for the arguments.
...

\`\`\`tool_calls
<tool_id>: { <JSON_serialized_tool_call_arguments> }
<tool_id_2>: { <JSON_serialized_tool_call_arguments_2> }
...
\`\`\`
```

:::note

The performance of this feature will vary greatly based on the LLM model you decide to use.

:::

## A tool example

Here is an example of a tool that generates a random number between 0 and 1.

```js
defTool("random", "Generate a random number", {}, () => Math.random())
$`Generate a random number between 0 and 1.`
```

- o1-mini trace (using GitHub Models)

````txt
prompting github:openai/o1-mini (~490 tokens)
```tool_calls
random: {}
```

prompting github:openai/o1-mini (~532 tokens)
Your random number between 0 and 1 is **0.7792901036554349**.
````

- gemma2 model (using Ollama)

````txt
prompting ollama:gemma2 (~716 tokens)

```tool_calls
random: {}
```
prompting ollama:gemma2 (~758 tokens)

The random number is 0.9552638470626966.


Let me know if you'd like to generate another random number!
````

## Activation

The fallback tool mode is automatically activated for known LLM models that don't support tools natively. The list is not complete
so open an issue if you stumble upon a model that should have fallback tools enabled.

It can be activated manually by setting the `fallbackTools` option to `true` in the script configuration.

```js
script({
    fallbackTools: true,
})
```

or by setting the `--fallback-tools` flag in the CLI.

```sh
genaiscript run --fallback-tools ...
```
